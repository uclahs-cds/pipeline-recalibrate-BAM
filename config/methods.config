includeConfig "${projectDir}/external/pipeline-Nextflow-config/config/csv/csv_parser.config"
includeConfig "${projectDir}/external/pipeline-Nextflow-config/config/bam/bam_parser.config"
includeConfig "${projectDir}/external/pipeline-Nextflow-config/config/methods/common_methods.config"
includeConfig "${projectDir}/external/pipeline-Nextflow-config/config/schema/schema.config"

methods {
    // Function to ensure that resource requirements don't go beyond
    // a maximum limit or below a minimum limit
    check_limits = { obj, type ->
        if (type == 'memory') {
            try {
                if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                    return params.max_memory as nextflow.util.MemoryUnit
                else if (obj.compareTo(params.min_memory as nextflow.util.MemoryUnit) == -1)
                    return params.min_memory as nextflow.util.MemoryUnit
                else
                    return obj
            } catch (all) {
                println "   ### WARNING ###   Max memory '${params.max_memory}' or min memory '${params.min_memory}' is not valid! Using default value: $obj"
                return obj
            }
        } else if (type == 'time') {
            try {
                if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                    return params.max_time as nextflow.util.Duration
                else if (obj.compareTo(params.min_time as nextflow.util.Duration) == -1)
                    return params.min_time as nextflow.util.Duration
                else
                    return obj
            } catch (all) {
                println "   ### WARNING ###   Max time '${params.max_time}' or min time '${params.min_time}' is not valid! Using default value: $obj"
                return obj
            }
        } else if (type == 'cpus') {
            try {
                return Math.max( Math.min( obj, params.max_cpus as int ), params.min_cpus as int )
            } catch (all) {
                println "   ### WARNING ###   Max cpus '${params.max_cpus}' or min cpus '${params.min_cpus}' is not valid! Using default value: $obj"
                return obj
            }
        }
    }

    set_log_output_dir = {
        def tz = TimeZone.getTimeZone("UTC")
        def date = new Date().format("yyyyMMdd'T'HHmmss'Z'", tz)

        params.log_output_dir = "${params.output_dir}/${manifest.name}-${manifest.version}/${params.sample_id}/log-${manifest.name}-${manifest.version}-${date}"
    }

    set_output_dir = {
        params.output_dir_base = "${params.output_dir}/${manifest.name}-${manifest.version}/${params.sample_id}/${params.docker_image_gatk.split("/")[1].replace(':', '-').toUpperCase()}"
    }

    /**
     * Check the permissions and existence of workDir.
     * If it doesn't exist, recursively find first existing directory and check write permission.
     * If it exists, check write permission.
     */
    check_workdir_permissions = { dir ->
        dir_file = new File(dir)
        if (dir_file.exists()) {
            if (dir_file.canWrite()) {
                return true
            } else {
                throw new Exception("   ### ERROR ###   The input directory params.work_dir: ${dir} is not writeable. Please verify and try again.")
            }
        } else {
            while (!dir_file.exists()) {
                dir_file = dir_file.getParentFile()
            }

            if (dir_file.canWrite()) {
                return true
            } else {
                throw new Exception("   ### ERROR ###   The input directory params.work_dir: ${dir} cannot be created. The closest existing parent directory ${dir_file.toString()} is not writable. Please verify permissions or change the input parameter.")
            }
        }
    }

    set_env = {
        if (params.ucla_cds) {
            /**
             * By default, if the /scratch directory exists, set it as the Nextflow working directory
             * If config file specified work_dir, set it as the Nextflow working directory
             *
             * WARNING: changing this directory can lead to high server latency and
             * potential disk space limitations. Change with caution! The 'workDir'
             * in Nextflow determines the location of intermediate and temporary files.
             */
            params.work_dir = (params.containsKey('work_dir') && params.work_dir) ? params.work_dir : '/scratch'
            if (methods.check_workdir_permissions(params.work_dir)) {
                workDir = params.work_dir
            }
        } else {
            // If work_dir was specified as a param and exists or can be created, set workDir. Otherwise, let Nextflow's default behavior dictate workDir
            if (params.containsKey('work_dir') && params.work_dir && methods.check_workdir_permissions(params.work_dir)) {
                workDir = params.work_dir
            }
        }
    }

    set_pipeline_logs = {
        trace.enabled = true
        trace.file = "${params.log_output_dir}/nextflow-log/trace.txt"

        timeline.enabled = true
        timeline.file = "${params.log_output_dir}/nextflow-log/timeline.html"

        report.enabled = true
        report.file = "${params.log_output_dir}/nextflow-log/report.html"
    }

    set_process = {
        process.cache = params.cache_intermediate_pipeline_steps
    }

    detect_mode = {
        // Detect whether job is for targeted sample
        params.is_targeted = (params.intervals) ? true : false
    }

    set_patient_id_from_csv = { List csv_input ->
        def patient_ids = [] as Set

        csv_input.each { csv_line -> [patient_ids.add(csv_line['patient_id'])] }
        if (patient_ids.size() != 1) {
            throw new Exception("Multiple patient IDs detected: ${patient_ids}. Please submit only a single patient per job.")
        }

        params.patient_id = patient_ids[0]
    }

    format_csv_input = { List csv_input ->
        params.input = ['BAM': '']
        
        def extracted_input = [] as Set

        csv_input.each { csv_line ->
            extracted_input.add(csv_line['BAM'])
        }

        if (extracted_input.size() != 1) {
            throw new Exception("Expected a single BAM but received: ${params.input.BAM}. Please submit only a single BAM.")
        }

        params.input.BAM = extracted_input[0]
    }

    convert_to_yaml_input = {
        if (params.containsKey('input')) {
            return
        } else if (params.containsKey('input_csv')) {
            def fields = ['patient_id', 'BAM']
            def raw_csv_input = csv_parser.parse_csv(params.input_csv, csv_header_fields)

            methods.set_patient_id_from_csv(raw_csv_input)

            methods.format_csv_input(raw_csv_input)
        } else {
            throw new Exception("Neither YAML nor CSV inputs found! Please run pipeline with inputs.")
        }
    }

    set_sample_id_from_bam = { String bam_path ->
        def bam_header = bam_parser.parse_bam_header(bam_path)
        def sm_tags = bam_header['read_group'].collect{ it['SM'] }.unique()

        if (sm_tags.size() != 1) {
            throw new Exception("BAM contains multiple samples! Please run pipeline with a single sample.")
        }

        params.sample_id = sm_tags[0]
    }

    setup = {
        methods.set_env()
        methods.set_resources_allocation()
        methods.convert_to_yaml_input()
        methods.set_sample_id_from_bam()
        methods.set_log_output_dir()
        methods.set_output_dir()
        methods.set_pipeline_logs()
        methods.set_process()
        methods.detect_mode()
    }
}
